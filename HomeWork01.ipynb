{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EliyaKaheni/ML-playground/blob/main/HomeWork01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcrsmfTV231a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "ya1B_ceY3EdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3im7ZuDq3DqH",
        "outputId": "9407c9fa-5e98-4616-cbce-e5c9faebe33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[np.random.randint(60000)], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "d3D1J4Uy3GPZ",
        "outputId": "0a8ddf20-0314-4ecf-e818-bce183e1df82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efbb14a0250>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "مقادیر دیتا را برای آموزش شبکه عصبی آماده کنید\n",
        " راهنمایی: عکس ها را به شکل آرایه دربیاورید و همجنین مقادیر آن ها را اسکیل کنید"
      ],
      "metadata": {
        "id": "dbJZspbu3Z7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 28*28)\n",
        "x_test = x_test.reshape(10000, 28*28)"
      ],
      "metadata": {
        "id": "zPBFffGq3Wgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "مقدار های خروجی را بصورت \n",
        "\n",
        "one hot encoding تبدیل کنید"
      ],
      "metadata": {
        "id": "3FkeabB44cMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)\n"
      ],
      "metadata": {
        "id": "e6aLnu8e4boG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[1:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "dQFVp1NHzHdy",
        "outputId": "ccbf5c82-a396-4f8e-bf9f-3d9dcbcb597d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9\n",
              "1  0  0  1  0  0  0  0  0  0  0\n",
              "2  0  1  0  0  0  0  0  0  0  0\n",
              "3  0  1  0  0  0  0  0  0  0  0\n",
              "4  0  0  0  0  0  0  1  0  0  0\n",
              "5  0  1  0  0  0  0  0  0  0  0\n",
              "6  0  0  0  0  1  0  0  0  0  0\n",
              "7  0  0  0  0  0  0  1  0  0  0\n",
              "8  0  0  0  0  0  1  0  0  0  0\n",
              "9  0  0  0  0  0  0  0  1  0  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a990505-cb6c-478e-8db3-c1637126f23f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a990505-cb6c-478e-8db3-c1637126f23f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a990505-cb6c-478e-8db3-c1637126f23f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a990505-cb6c-478e-8db3-c1637126f23f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "یک مدل بر پایه شبکه عصبی طراحی کنید که دسته بندی را انجام دهد\n",
        "\n",
        "\n",
        "هدف از تمرین حداقل درصد 80 میباشد\n",
        "\n",
        "\n",
        "تعداد لایه ها و نوع آن ها به علاوه تعداد ایپاک ها و بچ سایز به انتخاب شماست و دلیل بیاورید که چرا این اندازه ها را انتخاب کرده اید"
      ],
      "metadata": {
        "id": "TrDRzXAJ3kw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(28 * 28, activation = \"relu\"))\n",
        "model.add(Dense(14 * 14, activation = \"relu\"))\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dense(10, activation = \"softmax\"))\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3t8aABjH3jNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build((None, 28*28))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkjOxSTh1KJT",
        "outputId": "2be9a93e-7b22-495b-adcf-276ad5d1bcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 196)               153860    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               50432     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 822,302\n",
            "Trainable params: 822,302\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size = 1024, epochs=100, validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "id": "TzbRzskQ4W6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a44d04-c38e-4937-e3d1-763ec63c2d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "59/59 [==============================] - 2s 9ms/step - loss: 15.4384 - accuracy: 0.6629 - val_loss: 1.5313 - val_accuracy: 0.7739\n",
            "Epoch 2/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 1.1375 - accuracy: 0.7984 - val_loss: 1.1124 - val_accuracy: 0.7927\n",
            "Epoch 3/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.8653 - accuracy: 0.8162 - val_loss: 0.8947 - val_accuracy: 0.8009\n",
            "Epoch 4/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.6507 - accuracy: 0.8345 - val_loss: 0.6918 - val_accuracy: 0.8317\n",
            "Epoch 5/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.8473 - val_loss: 0.6739 - val_accuracy: 0.8262\n",
            "Epoch 6/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.8562 - val_loss: 0.5827 - val_accuracy: 0.8369\n",
            "Epoch 7/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8698 - val_loss: 0.5472 - val_accuracy: 0.8456\n",
            "Epoch 8/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.8753 - val_loss: 0.5168 - val_accuracy: 0.8452\n",
            "Epoch 9/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3452 - accuracy: 0.8827 - val_loss: 0.5012 - val_accuracy: 0.8550\n",
            "Epoch 10/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8802 - val_loss: 0.5240 - val_accuracy: 0.8544\n",
            "Epoch 11/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8866 - val_loss: 0.4748 - val_accuracy: 0.8552\n",
            "Epoch 12/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.2938 - accuracy: 0.8953 - val_loss: 0.5079 - val_accuracy: 0.8534\n",
            "Epoch 13/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.2959 - accuracy: 0.8958 - val_loss: 0.4684 - val_accuracy: 0.8597\n",
            "Epoch 14/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.2897 - accuracy: 0.8964 - val_loss: 0.5131 - val_accuracy: 0.8559\n",
            "Epoch 15/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.2725 - accuracy: 0.9027 - val_loss: 0.4489 - val_accuracy: 0.8647\n",
            "Epoch 16/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.2579 - accuracy: 0.9083 - val_loss: 0.5268 - val_accuracy: 0.8489\n",
            "Epoch 17/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.2416 - accuracy: 0.9122 - val_loss: 0.4801 - val_accuracy: 0.8584\n",
            "Epoch 18/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.2470 - accuracy: 0.9098 - val_loss: 0.4752 - val_accuracy: 0.8626\n",
            "Epoch 19/100\n",
            "59/59 [==============================] - 0s 7ms/step - loss: 0.2370 - accuracy: 0.9137 - val_loss: 0.4663 - val_accuracy: 0.8614\n",
            "Epoch 20/100\n",
            "59/59 [==============================] - 0s 7ms/step - loss: 0.2373 - accuracy: 0.9129 - val_loss: 0.4491 - val_accuracy: 0.8668\n",
            "Epoch 21/100\n",
            "59/59 [==============================] - 0s 7ms/step - loss: 0.2165 - accuracy: 0.9204 - val_loss: 0.4530 - val_accuracy: 0.8709\n",
            "Epoch 22/100\n",
            "59/59 [==============================] - 0s 7ms/step - loss: 0.2117 - accuracy: 0.9229 - val_loss: 0.4388 - val_accuracy: 0.8745\n",
            "Epoch 23/100\n",
            "59/59 [==============================] - 0s 8ms/step - loss: 0.1969 - accuracy: 0.9266 - val_loss: 0.4463 - val_accuracy: 0.8739\n",
            "Epoch 24/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.2031 - accuracy: 0.9244 - val_loss: 0.4736 - val_accuracy: 0.8660\n",
            "Epoch 25/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.9275 - val_loss: 0.4446 - val_accuracy: 0.8740\n",
            "Epoch 26/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1959 - accuracy: 0.9280 - val_loss: 0.4618 - val_accuracy: 0.8655\n",
            "Epoch 27/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1957 - accuracy: 0.9274 - val_loss: 0.4539 - val_accuracy: 0.8722\n",
            "Epoch 28/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1760 - accuracy: 0.9354 - val_loss: 0.4321 - val_accuracy: 0.8788\n",
            "Epoch 29/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1760 - accuracy: 0.9349 - val_loss: 0.4362 - val_accuracy: 0.8743\n",
            "Epoch 30/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1852 - accuracy: 0.9340 - val_loss: 0.4873 - val_accuracy: 0.8628\n",
            "Epoch 31/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1831 - accuracy: 0.9324 - val_loss: 0.4367 - val_accuracy: 0.8769\n",
            "Epoch 32/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1686 - accuracy: 0.9379 - val_loss: 0.4461 - val_accuracy: 0.8724\n",
            "Epoch 33/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1611 - accuracy: 0.9412 - val_loss: 0.4620 - val_accuracy: 0.8704\n",
            "Epoch 34/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1692 - accuracy: 0.9375 - val_loss: 0.4514 - val_accuracy: 0.8772\n",
            "Epoch 35/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1621 - accuracy: 0.9405 - val_loss: 0.4650 - val_accuracy: 0.8725\n",
            "Epoch 36/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1593 - accuracy: 0.9406 - val_loss: 0.4582 - val_accuracy: 0.8775\n",
            "Epoch 37/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1564 - accuracy: 0.9421 - val_loss: 0.4545 - val_accuracy: 0.8760\n",
            "Epoch 38/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1468 - accuracy: 0.9453 - val_loss: 0.4556 - val_accuracy: 0.8796\n",
            "Epoch 39/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1511 - accuracy: 0.9441 - val_loss: 0.4937 - val_accuracy: 0.8726\n",
            "Epoch 40/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1451 - accuracy: 0.9466 - val_loss: 0.4580 - val_accuracy: 0.8786\n",
            "Epoch 41/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1537 - accuracy: 0.9432 - val_loss: 0.4640 - val_accuracy: 0.8819\n",
            "Epoch 42/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1436 - accuracy: 0.9482 - val_loss: 0.5070 - val_accuracy: 0.8693\n",
            "Epoch 43/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1453 - accuracy: 0.9461 - val_loss: 0.5020 - val_accuracy: 0.8759\n",
            "Epoch 44/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.9452 - val_loss: 0.4735 - val_accuracy: 0.8792\n",
            "Epoch 45/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1533 - accuracy: 0.9435 - val_loss: 0.4944 - val_accuracy: 0.8725\n",
            "Epoch 46/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1477 - accuracy: 0.9463 - val_loss: 0.4989 - val_accuracy: 0.8685\n",
            "Epoch 47/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.9453 - val_loss: 0.4965 - val_accuracy: 0.8765\n",
            "Epoch 48/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1463 - accuracy: 0.9467 - val_loss: 0.4945 - val_accuracy: 0.8716\n",
            "Epoch 49/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1399 - accuracy: 0.9492 - val_loss: 0.5355 - val_accuracy: 0.8748\n",
            "Epoch 50/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1378 - accuracy: 0.9491 - val_loss: 0.4926 - val_accuracy: 0.8789\n",
            "Epoch 51/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1230 - accuracy: 0.9540 - val_loss: 0.5075 - val_accuracy: 0.8830\n",
            "Epoch 52/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9514 - val_loss: 0.5102 - val_accuracy: 0.8781\n",
            "Epoch 53/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9543 - val_loss: 0.4863 - val_accuracy: 0.8841\n",
            "Epoch 54/100\n",
            "59/59 [==============================] - 0s 7ms/step - loss: 0.1325 - accuracy: 0.9503 - val_loss: 0.4888 - val_accuracy: 0.8848\n",
            "Epoch 55/100\n",
            "59/59 [==============================] - 0s 8ms/step - loss: 0.1426 - accuracy: 0.9475 - val_loss: 0.5374 - val_accuracy: 0.8672\n",
            "Epoch 56/100\n",
            "59/59 [==============================] - 0s 7ms/step - loss: 0.1384 - accuracy: 0.9502 - val_loss: 0.4886 - val_accuracy: 0.8789\n",
            "Epoch 57/100\n",
            "59/59 [==============================] - 0s 8ms/step - loss: 0.1342 - accuracy: 0.9510 - val_loss: 0.5034 - val_accuracy: 0.8845\n",
            "Epoch 58/100\n",
            "59/59 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.9470 - val_loss: 0.5626 - val_accuracy: 0.8685\n",
            "Epoch 59/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1476 - accuracy: 0.9459 - val_loss: 0.5196 - val_accuracy: 0.8698\n",
            "Epoch 60/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1210 - accuracy: 0.9553 - val_loss: 0.5144 - val_accuracy: 0.8779\n",
            "Epoch 61/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.9558 - val_loss: 0.5120 - val_accuracy: 0.8822\n",
            "Epoch 62/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1244 - accuracy: 0.9544 - val_loss: 0.5107 - val_accuracy: 0.8793\n",
            "Epoch 63/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9568 - val_loss: 0.5236 - val_accuracy: 0.8763\n",
            "Epoch 64/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1362 - accuracy: 0.9507 - val_loss: 0.5181 - val_accuracy: 0.8835\n",
            "Epoch 65/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.9570 - val_loss: 0.5389 - val_accuracy: 0.8794\n",
            "Epoch 66/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1213 - accuracy: 0.9558 - val_loss: 0.5164 - val_accuracy: 0.8843\n",
            "Epoch 67/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1302 - accuracy: 0.9529 - val_loss: 0.5365 - val_accuracy: 0.8785\n",
            "Epoch 68/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1212 - accuracy: 0.9556 - val_loss: 0.5492 - val_accuracy: 0.8801\n",
            "Epoch 69/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9554 - val_loss: 0.5583 - val_accuracy: 0.8861\n",
            "Epoch 70/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1352 - accuracy: 0.9511 - val_loss: 0.5466 - val_accuracy: 0.8742\n",
            "Epoch 71/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1575 - accuracy: 0.9437 - val_loss: 0.5366 - val_accuracy: 0.8738\n",
            "Epoch 72/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1328 - accuracy: 0.9525 - val_loss: 0.5102 - val_accuracy: 0.8802\n",
            "Epoch 73/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1199 - accuracy: 0.9563 - val_loss: 0.5287 - val_accuracy: 0.8822\n",
            "Epoch 74/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1365 - accuracy: 0.9508 - val_loss: 0.6012 - val_accuracy: 0.8617\n",
            "Epoch 75/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1578 - accuracy: 0.9430 - val_loss: 0.5545 - val_accuracy: 0.8798\n",
            "Epoch 76/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1176 - accuracy: 0.9575 - val_loss: 0.5289 - val_accuracy: 0.8812\n",
            "Epoch 77/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.9581 - val_loss: 0.5023 - val_accuracy: 0.8889\n",
            "Epoch 78/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1049 - accuracy: 0.9612 - val_loss: 0.5791 - val_accuracy: 0.8833\n",
            "Epoch 79/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9542 - val_loss: 0.5403 - val_accuracy: 0.8887\n",
            "Epoch 80/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9604 - val_loss: 0.5251 - val_accuracy: 0.8842\n",
            "Epoch 81/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9601 - val_loss: 0.5455 - val_accuracy: 0.8849\n",
            "Epoch 82/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.9604 - val_loss: 0.5872 - val_accuracy: 0.8752\n",
            "Epoch 83/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9585 - val_loss: 0.5502 - val_accuracy: 0.8804\n",
            "Epoch 84/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1124 - accuracy: 0.9595 - val_loss: 0.5426 - val_accuracy: 0.8845\n",
            "Epoch 85/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9656 - val_loss: 0.5670 - val_accuracy: 0.8861\n",
            "Epoch 86/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9658 - val_loss: 0.5680 - val_accuracy: 0.8854\n",
            "Epoch 87/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.9675 - val_loss: 0.5772 - val_accuracy: 0.8797\n",
            "Epoch 88/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1317 - accuracy: 0.9541 - val_loss: 0.6133 - val_accuracy: 0.8710\n",
            "Epoch 89/100\n",
            "59/59 [==============================] - 0s 7ms/step - loss: 0.1401 - accuracy: 0.9506 - val_loss: 0.6084 - val_accuracy: 0.8781\n",
            "Epoch 90/100\n",
            "59/59 [==============================] - 0s 7ms/step - loss: 0.1180 - accuracy: 0.9571 - val_loss: 0.5647 - val_accuracy: 0.8830\n",
            "Epoch 91/100\n",
            "59/59 [==============================] - 0s 7ms/step - loss: 0.1124 - accuracy: 0.9598 - val_loss: 0.5832 - val_accuracy: 0.8820\n",
            "Epoch 92/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1261 - accuracy: 0.9560 - val_loss: 0.6221 - val_accuracy: 0.8722\n",
            "Epoch 93/100\n",
            "59/59 [==============================] - 0s 8ms/step - loss: 0.1301 - accuracy: 0.9548 - val_loss: 0.5773 - val_accuracy: 0.8826\n",
            "Epoch 94/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.9609 - val_loss: 0.5486 - val_accuracy: 0.8871\n",
            "Epoch 95/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.1265 - accuracy: 0.9552 - val_loss: 0.5550 - val_accuracy: 0.8821\n",
            "Epoch 96/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9665 - val_loss: 0.5754 - val_accuracy: 0.8865\n",
            "Epoch 97/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.0926 - accuracy: 0.9657 - val_loss: 0.5737 - val_accuracy: 0.8866\n",
            "Epoch 98/100\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9660 - val_loss: 0.5758 - val_accuracy: 0.8874\n",
            "Epoch 99/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.9643 - val_loss: 0.6317 - val_accuracy: 0.8809\n",
            "Epoch 100/100\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.1160 - accuracy: 0.9582 - val_loss: 0.5687 - val_accuracy: 0.8845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M47wVpC34u8K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}